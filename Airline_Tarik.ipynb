{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-IA-2022/Airline_Tarik/blob/main/Airline_Tarik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0hEus8R36qI"
      },
      "source": [
        "#Sentiment Analysis - Airline Passenger Satisfaction\n",
        "\n",
        "\n",
        "-----\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://simplonline.co/_next/image?url=https%3A%2F%2Fsimplonline-v3-prod.s3.eu-west-3.amazonaws.com%2Fmedia%2Fimage%2Fjpg%2F64814-shutterstock-1073953772-642497423efc3496249445.jpg&w=1280&q=75\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdLVT_fQ7Hp3"
      },
      "source": [
        "## Objectifs\n",
        "A partir d'une enquête de satisfaction menée sur un ensemble de 130 000 passagers, vous devez mettre en oeuvre une démarche de machine learning : \n",
        "- pour comprendre quelles sont les informations qui influent sur la satisfaction / insatisfaction d'un passager\n",
        "- pour prédire la satisfaction / insatisfaction d'un passager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjK-04U7a_2"
      },
      "source": [
        "## EDA (Exploratory Data Analysis) sur le jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coVjPwc72w6h",
        "outputId": "99dc3185-43cc-486e-cca9-58373beb5ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQEbczcU-I3P"
      },
      "source": [
        "## 1.Le jeu de données\n",
        "Le jeu de données est disponible ci-dessous.  \n",
        "Il concerne la satisfaction client selon différentes caractéristiques :\n",
        "* la cible à prédire est la colonne `Satisfaction`\n",
        "* les features (numériques et catégorielles) sont toutes les autres colonnes :\n",
        "  - `Age`:L'age des passagers\n",
        "  -  `Gender`: Le genre des passagers (Femme, Homme)\n",
        "  -  `Type of Travel`: Le but du voyage des passagers (Voyage personnel, Voyage d'affaires)\n",
        "  -  `Class`: La classe de voyage dans l'avion des passagers (Affaires, Économique, Économique Plus)\n",
        "  -  `Customer Type`: Le type de client (Client fidèle, client infidèle)\n",
        "  -  `Flight distance`: La distance de vol de ce voyage\n",
        "  -  `Inflight wifi service`: Le niveau de satisfaction du service wifi à bord (0: Non applicable; 1-5)\n",
        "  -  `Ease of Online booking`: Le niveau de satisfaction de la réservation en ligne\n",
        "  -  `Inflight service`: Le niveau de satisfaction du service à bord\n",
        "  -  `Online boarding`: Le niveau de satisfaction de l'embarquement en ligne\n",
        "  -  `Inflight entertainment`: Le niveau de satisfaction du divertissement à bord\n",
        "  -  `Food and drink`: Le niveau de satisfaction de la nourriture et de la boisson\n",
        "  -  `Seat comfort`: Le niveau de satisfaction du confort des sièges\n",
        "  -  `On-board service`: Le niveau de satisfaction du service à bord\n",
        "  -  `Leg room service`: Le niveau de satisfaction de l'espace pour les jambes\n",
        "  -  `Departure/Arrival time convenient`: Le niveau de satisfaction de la convenance de l'heure de départ/arrivée\n",
        "  -  `Baggage handling`: Le niveau de satisfaction de la gestion des bagages\n",
        "  -  `Gate location`: Le niveau de satisfaction de l'emplacement de la porte\n",
        "  -  `Cleanliness`: Le niveau de satisfaction de la propreté\n",
        "  -  `Check-in service`: Le niveau de satisfaction du service d'enregistrement\n",
        "  -  `Departure Delay in Minutes`: Les minutes de retard au départ\n",
        "  -  `Arrival Delay in Minutes`: Les minutes de retard à l'arrivée\n",
        "  -  `Flight cancelled`: Si le vol a été annulé ou non (Oui, Non)\n",
        "  -  `Flight time in minutes`: Les minutes de la durée de vol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW6_5-zzDL1o"
      },
      "source": [
        "## 2.Les librairies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23\n",
        "!pip install dython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "7LKwu5VfPEVk",
        "outputId": "7533a885-1113-4045-d579-426f3ed59d2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "Successfully installed numpy-1.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dython\n",
            "  Downloading dython-0.7.3-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.9/dist-packages (from dython) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.4.2 in /usr/local/lib/python3.9/dist-packages (from dython) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from dython) (1.10.1)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.9/dist-packages (from dython) (0.12.2)\n",
            "Collecting scikit-plot>=0.3.7\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.9/dist-packages (from dython) (5.9.4)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.9/dist-packages (from dython) (1.23.0)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.9/dist-packages (from dython) (3.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.5.3->dython) (8.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.4.2->dython) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.2->dython) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.2->dython) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.5.3->dython) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->dython) (1.16.0)\n",
            "Installing collected packages: scikit-plot, dython\n",
            "Successfully installed dython-0.7.3 scikit-plot-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XOtvEZZUDS5w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "b9ddcdb2-30e1-4d74-aa2f-55c3bafc9401"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6bc19ce08cfc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnominal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massociations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manova\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manova_lm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/dython/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnominal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_version_from_setuptools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/dython/nominal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpsutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    483\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 485\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munittest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTestCase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_assert_valid_refcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gen_alignment_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorators\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m from numpy.core import(\n\u001b[1;32m     22\u001b[0m      intp, float32, empty, arange, array_repr, ndarray, isnat, array)\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlapack_lite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Import et traitement des données\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#correlation\n",
        "from dython.nominal import associations\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "# Graphiques\n",
        "import seaborn as sns ; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning - Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler, StandardScaler #MinMaxScaler, \n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Machine learning - Automatisation\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import set_config\n",
        "\n",
        "# Machine learning - Modèle d'apprentissage supervisé\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Machine learning - Modèle selection\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, HalvingGridSearchCV\n",
        "\n",
        "# Machine learning - Métriques d'erreur\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay, f1_score, fbeta_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22njsSI77GoX"
      },
      "outputs": [],
      "source": [
        "# read csv\n",
        "url = \"https://raw.githubusercontent.com/remijul/dataset/master/Airline%20Passenger%20Satisfaction.csv\"\n",
        "df = pd.read_csv(url, encoding='utf-8', sep=';')\n",
        "df.drop(['id'], axis=1, inplace=True)\n",
        "df.columns = df.columns.str.replace(\" \", \"_\")\n",
        "df.columns = df.columns.str.replace(\"-\", \"_\")\n",
        "df.columns = df.columns.str.replace(\"/\", \"_\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTjCh-pEhbh"
      },
      "source": [
        "## 3.Analyse de données exploratoire (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABSDGSexFhUY"
      },
      "source": [
        "### 3.1 Description du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xw33fu3EgcY"
      },
      "outputs": [],
      "source": [
        "# Dimmension du jeu de données\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29_Xrx5a4amU"
      },
      "outputs": [],
      "source": [
        "# Nom et types\n",
        "df.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypMTzFJWEzld"
      },
      "outputs": [],
      "source": [
        "# Infos\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P6LjRo2FJN4"
      },
      "source": [
        "###Données manquantes?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nt0wlgQFAFi"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayfPczbvFoLY"
      },
      "source": [
        "### 3.2 Analyse univariée \n",
        "Description statistique des données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DttgKI32Fpmg"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVdolwaCHCQY"
      },
      "source": [
        "### 3.3 Analyse bivariée - Variables numériques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wumQ3CEKHLg4"
      },
      "source": [
        "Distribution de la target en fonction des variables numériques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW5meu1ZITs4"
      },
      "outputs": [],
      "source": [
        "#df_eda\n",
        "df_eda = df.replace(['Male', 'Female'],[0, 1])\n",
        "df_eda['Arrival_Delay_in_Minutes'] = df['Arrival_Delay_in_Minutes'].fillna(df['Departure_Delay_in_Minutes'])\n",
        "# df_eda['Arrival Delay in Minutes'] = df_eda['Arrival Delay in Minutes'].astype('int64')\n",
        "df_eda.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCEDLOr9SrC7"
      },
      "outputs": [],
      "source": [
        "# create a dataframe\n",
        "dataframe = pd.DataFrame(df_eda, columns = ['Satisfaction',\t'Gender',\t'Customer', 'Type_Age','Departure_Delay_in_Minutes',\t'Arrival_Delay_in_Minutes' ])\n",
        "\n",
        "  \n",
        "# selecting rows based on condition\n",
        "rslt_df = dataframe[dataframe['Arrival_Delay_in_Minutes'].isna() ]\n",
        "rslt_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXEThDvBHBkg"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(figsize=(16, 10))\n",
        "\n",
        "# Plot variable 1\n",
        "ax1 = plt.subplot(2,2,1)\n",
        "sns.histplot(data=df_eda, x=\"Class\", hue=\"Satisfaction\", kde=True)\n",
        "\n",
        "# Plot variable 2\n",
        "ax1 = plt.subplot(2,2,2)\n",
        "sns.histplot(data=df_eda, x=\"Age\", hue=\"Satisfaction\", kde=True)\n",
        "\n",
        "# Plot variable 3\n",
        "ax1 = plt.subplot(2,2,3)\n",
        "sns.histplot(data=df_eda, x=\"Flight_Distance\", hue=\"Satisfaction\", kde=True)\n",
        "\n",
        "# Plot variable 4\n",
        "ax1 = plt.subplot(2,2,4)\n",
        "sns.histplot(data=df_eda, x=\"Type_of_Travel\", hue=\"Satisfaction\", kde=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zg2iYO9CNhJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-k0gUIvfuUU"
      },
      "source": [
        "### 3.4 Data correlation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identification des colonnes categorielle avec dython comme le select_dtypes(include=['object']) de pandas\n",
        "from dython.nominal import identify_nominal_columns\n",
        "categorical_features=identify_nominal_columns(df_eda)\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "9sdT0sO8OXDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#option de la fonction association qui retourne la matrice de correlation corr et le graphique de cette dernière ax (matplotlib)\n",
        "#   associations(dataset, nominal_columns='auto', numerical_columns=None, mark_columns=False, nom_nom_assoc='cramer', num_num_assoc='pearson', bias_correction=True, nan_strategy=_REPLACE, nan_replace_value=_DEFAULT_REPLACE_VALUE, ax=None, figsize=None, annot=True, fmt='.2f', cmap=None, sv_color='silver', cbar=True, vmax=1.0, vmin=None, plot=True, compute_only=False, clustering=False, title=None, filename=None)"
      ],
      "metadata": {
        "id": "Q8JmF8wVRW_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_correlation= associations(df_eda,  filename= 'complete_correlation.png', figsize=(16,16))"
      ],
      "metadata": {
        "id": "N9TkDMKhRzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8qGFtB0doGU"
      },
      "outputs": [],
      "source": [
        "# convert categorical variables to numerical variables\n",
        "# df_eda = pd.get_dummies(df_eda)\n",
        "\n",
        "# create correlation matrix\n",
        "# corr_matrix = df_eda.corr()\n",
        "corr_matrix = complete_correlation['corr']\n",
        "# # select only columns with correlation > 0.3 with the target variable 'Satisfaction'\n",
        "# corr_cols = corr_matrix.loc[corr_matrix['Satisfaction_satisfied'] > 0.25, 'Satisfaction_satisfied'].sort_values(ascending=False)\n",
        "corr_cols = corr_matrix.loc[corr_matrix['Satisfaction'] > 0.22, 'Satisfaction'].sort_values(ascending=False)\n",
        "# print the resulting correlation matrix\n",
        "corr_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Anova"
      ],
      "metadata": {
        "id": "FYrT4IRLweAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "def anova_test(df, target_col):\n",
        "    \"\"\"\n",
        "    Performs ANOVA test between each numerical feature in the dataframe and the target variable\n",
        "    specified by target_col and returns a new dataframe containing the F-score and p-value\n",
        "    for each test.\n",
        "    \n",
        "    Args:\n",
        "    df (pandas.DataFrame): the input dataframe\n",
        "    target_col (str): the name of the target column in the dataframe\n",
        "    \n",
        "    Returns:\n",
        "    pandas.DataFrame: a dataframe containing the F-score and p-value for each ANOVA test.\n",
        "    \"\"\"\n",
        "    p_values = []\n",
        "    f_scores = []\n",
        "    columns = []\n",
        "    \n",
        "    # Perform ANOVA test for each numerical column in the dataframe\n",
        "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
        "        if col != target_col:\n",
        "            category_groups = [df[df[target_col] == category][col] for category in df[target_col].unique()]\n",
        "            f, p = f_oneway(*category_groups)\n",
        "            p_values.append(p)\n",
        "            f_scores.append(f)\n",
        "            columns.append(col)\n",
        "    \n",
        "    # Create a new dataframe with the results\n",
        "    results_df = pd.DataFrame({'Feature': columns, 'F-score': f_scores, 'p-value': p_values})\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "VWFYU1wjQmLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "0ohGEbRPOM5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anova_df = anova_test(df_eda, \"Satisfaction\")\n",
        "anova_df"
      ],
      "metadata": {
        "id": "L1vHgFtXQuZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_features = anova_df.sort_values(by=['F-score'], ascending=False)['Feature'].tolist()\n",
        "sorted_features"
      ],
      "metadata": {
        "id": "GEMSl00DTj_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imyr0jttshgF"
      },
      "source": [
        "###On observe que:\n",
        "les features les plus corrélées avec la satisfaction client sont les services à bord avec:\n",
        " - divertissement à bord,\n",
        " - la class,\n",
        " - l'espace pour les jambes(normale ^^)\n",
        " - baggages,\n",
        " - enregistrement,\n",
        " - propreté\n",
        "\n",
        "et les services en lignes:\n",
        " - le support en ligne,\n",
        " - Online_boarding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rak6f9L_jcSF"
      },
      "outputs": [],
      "source": [
        "#matrice correlation\n",
        "sns.heatmap(df_eda[['Inflight_entertainment', 'Online_support', 'Ease_of_Online_booking',\n",
        "                    'On_board_service', 'Leg_room_service', 'Baggage_handling', 'Checkin_service',\n",
        "                    'Cleanliness', 'Online_boarding']].corr(), annot=True, linewidths=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les features "
      ],
      "metadata": {
        "id": "Xp4eMg3wE3lO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiVBUMLc0KnO"
      },
      "source": [
        "## 4.Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B4FG3ia0MaG"
      },
      "source": [
        "### 4.1 Preprocessing sur la cible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W154ENZ0U8-"
      },
      "source": [
        "Sélection de la variable cible (target) `Satisfaction`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vucSLYtXoutF"
      },
      "outputs": [],
      "source": [
        "y = df['Satisfaction']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhFt4uHv7TKP"
      },
      "source": [
        "### 4.2 Preprocessing sur les features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFslEOZ7hXn"
      },
      "source": [
        "Features preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWwpspHY6vXQ"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns='Satisfaction')\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYJU3xTe8J_3"
      },
      "source": [
        "#### 4.2.1 Variables catégorielles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdETTtub8OKH"
      },
      "source": [
        "Selection des variables categorielles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxjVPjNs8I_J"
      },
      "outputs": [],
      "source": [
        "column_cat = X.select_dtypes(include=['object']).columns\n",
        "column_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CenBGyYe8ac_"
      },
      "source": [
        "Déclaration de la méthode de preprocessing sur les variables catégorielles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74tglS-j8bXH"
      },
      "outputs": [],
      "source": [
        "transfo_cat = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output = False))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsVXsPoY9voI"
      },
      "source": [
        "#### 4.2.2 Variables numériques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGymmMU69zRf"
      },
      "source": [
        "Selection des variables numériques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2_86iM29waX"
      },
      "outputs": [],
      "source": [
        "column_num = X.select_dtypes(exclude=['object']).columns\n",
        "column_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvk2icZz9-Sm"
      },
      "source": [
        "Déclaration de la méthode de preprocessing sur les variables numériques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIdSG1Z99N_"
      },
      "outputs": [],
      "source": [
        "transfo_num = Pipeline(steps=[\n",
        "    ('imputation', KNNImputer(n_neighbors=3, weights=\"uniform\")),\n",
        "    ('scaling', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4FPlXPJBRPX"
      },
      "source": [
        "#### 4.2.3 Transformation des features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZRyCndgBSPv"
      },
      "outputs": [],
      "source": [
        "preparation = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('data_cat', transfo_cat , column_cat),\n",
        "        ('data_num', transfo_num , column_num)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtQ1X1W0CHig"
      },
      "outputs": [],
      "source": [
        "set_config(display=\"diagram\")\n",
        "preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWvhS8aDCQLZ"
      },
      "source": [
        "### 4.3 Répartition `train-test-split` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_cG57Z4CPTo"
      },
      "outputs": [],
      "source": [
        "# Noter la présence du stratify sur la target pour mieux équilibrer les observation sur la target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFPOIhrrIg-L"
      },
      "source": [
        "## 5.Entrainement du modèle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB48fmUoIs2L"
      },
      "source": [
        "### 5.1 Premier essai : `KNeighboursClassifier`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPb8bTgPQmGG"
      },
      "outputs": [],
      "source": [
        "clf = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V545JM5P4YH"
      },
      "source": [
        "#### 5.1.1 Déclaration du modèle\n",
        "Déclaration du modèle sans paramétrage.\n",
        "Documentation [KNC()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phFMesRcJCIK"
      },
      "source": [
        "#### 5.1.2 Intégration dans le pipeline\n",
        "Intégration du modèle d'apprentissage dans le pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15IyEneDM1Sh"
      },
      "outputs": [],
      "source": [
        "model = Pipeline(steps=[('preparation', preparation),\n",
        "                        ('model', clf)])\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ctUBWDCPvSP"
      },
      "source": [
        "#### 5.1.3 Apprentissage\n",
        "Phase d'apprentissage du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esTBmE-dG_VE"
      },
      "outputs": [],
      "source": [
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "# Fit the pipeline to the training data and evaluate it using cross-validation\n",
        "model.fit(X_train, y_train)\n",
        "scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
        "\n",
        "# Print the mean score and the standard deviation\n",
        "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdqELsMSRBwv"
      },
      "source": [
        "#### 5.1.4 Prédictions\n",
        "Utiliser du jeu de test pour réaliser les prédictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEtWpqp6RDBu"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR0cTcBqRjbu"
      },
      "source": [
        "#### 5.1.5 Evaluation\n",
        "Evaluation de la performance (`accuracy score`) du modèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiOg5bR3Rkiv"
      },
      "outputs": [],
      "source": [
        "score = accuracy_score(y_test, y_pred)\n",
        "print(f\"Performance du modèle {clf} - Accuracy score :\", round(score, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAp07xo7YlZG"
      },
      "source": [
        "Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMx1jq3JYmcu"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB1r7UNFYs1V"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"dark\")\n",
        "\n",
        "cm_plot = ConfusionMatrixDisplay(conf_matrix,\n",
        "                                display_labels=df['Satisfaction'].unique())\n",
        "\n",
        "cm_plot.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_R6OuKOZO2N"
      },
      "source": [
        "## 6.Comparaison de modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enN9JQzpZTQF"
      },
      "source": [
        "### 6.1 Construction d'une fonction `getClassifResults()`\n",
        "Pour faciliter le processus complet d'entrainement et d'évaluation du modèle, nous allons créer ici une fonction qui fait l'intégralité du processus d'apprentissage supervisé et qui restitue les performances du modèle.  \n",
        "\n",
        "La fonction `getClassifResults()` prend comme paramètres d'entrée :  \n",
        "* `classifier` : le modèle de classification que nous souhaitons utiliser.\n",
        "* `parameters` : la liste des hyper-paramètres et de leurs valeurs qui souhaitons étudier dans le processus `GridSearchCV`, au format dictionnaire.\n",
        "* `data` : la dataframe sur laquelle nous souhaitons réaliser le processus d'apprentissage supervisé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apRJT9DqZNb8"
      },
      "outputs": [],
      "source": [
        "def getClassifResults(classifier, parameters, data):\n",
        "\n",
        "  # PREPROCESSING\n",
        "  # Target\n",
        "  y = data['Satisfaction']\n",
        "  \n",
        "  # Features preprocessing\n",
        "  X = data.drop(columns='Satisfaction')\n",
        "  \n",
        "  column_cat = X.select_dtypes(include=['object']).columns\n",
        "  transfo_cat = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
        "  ])\n",
        "  \n",
        "  column_num = X.select_dtypes(exclude=['object']).columns\n",
        "  transfo_num = Pipeline(steps=[\n",
        "    ('imputation', KNNImputer(n_neighbors=3, weights=\"uniform\")),\n",
        "    ('scaling', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  preparation = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('data_cat', transfo_cat , column_cat),\n",
        "        ('data_num', transfo_num , column_num)\n",
        "    ])\n",
        "\n",
        "  # train-test-split\t\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2, stratify=y)\t\n",
        "\n",
        "  # Pipeline and Model\n",
        "  model = Pipeline(steps=[('preparation', preparation),\n",
        "                          ('model', classifier)])\n",
        "\n",
        "  # Define the cross-validation strategy\n",
        "  cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "  # Gridsearch\n",
        "  grid = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'f1_weighted', cv = cv, n_jobs =-1, verbose = 2)\n",
        "  \n",
        "  #grid = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'f1_weighted', cv = 5, n_jobs =-1, verbose = 0)\n",
        "\n",
        "  # Fit\n",
        "  grid.fit(X_train, y_train)\n",
        "\n",
        "  # Predict\n",
        "  y_pred = grid.predict(X_test)\n",
        "  y_train_pred = grid.predict(X_train)\n",
        "  train_accu_score = accuracy_score(y_train, y_train_pred)\n",
        "  test_f1_score = fbeta_score(y_test, y_pred, average='weighted', beta=0.5)\n",
        "  test_accu_score = accuracy_score(y_test, y_pred)\n",
        "  # Results\n",
        "  classifier_results = []\n",
        "  classifier_results.append(grid.cv_results_['mean_fit_time'].mean().round(4))\n",
        "  classifier_results.append(grid.best_score_.round(4))\n",
        "  classifier_results.append(train_accu_score.round(4))\n",
        "  classifier_results.append(test_f1_score.round(4))\n",
        "  classifier_results.append(test_accu_score.round(4))\n",
        "  classifier_results.append(grid.best_params_)\n",
        "\n",
        "  return  classifier_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##création d'un dictionnaire de model a tester"
      ],
      "metadata": {
        "id": "JBPK19ScrCiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    'KNeighborsClassifier': {'model__n_neighbors': range(1, 10, 2)},\n",
        "    'RandomForestClassifier': {'model__n_estimators': range(50, 500, 50), 'model__criterion': ('gini', 'entropy')},\n",
        "    'HistGradientBoostingClassifier': {'model__learning_rate': np.arange(start=0.1, stop=0.9, step=0.1), 'model__loss': ('auto', 'binary_crossentropy')}\n",
        "}"
      ],
      "metadata": {
        "id": "UOfnTW_-rBBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Itération dans le dict et utilisation de la fonction, save dans un dict"
      ],
      "metadata": {
        "id": "-lT-rP3urWWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for classifier_name in classifiers.keys():\n",
        "    classifier = globals()[classifier_name]()\n",
        "    parameters = classifiers[classifier_name]\n",
        "    res = getClassifResults(classifier, parameters, data=df)\n",
        "    results[classifier_name] = res"
      ],
      "metadata": {
        "id": "dapTo62Brg-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Génération du rapport avec plot matrice de confusion"
      ],
      "metadata": {
        "id": "nGhfB6kMr_eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(index=['Testing time (sec)', 'Training score (F1-score)', 'Training score (accuracy stratKfold)', 'Evaluation score (F1-score)', 'Evaluation score (accuracy stratKfold)', 'Best parameters'])\n",
        "confusion_matrices = {}\n",
        "\n",
        "for classifier_name in results.keys():\n",
        "    res = results[classifier_name]\n",
        "    results_df[classifier_name] = res\n",
        "    classifier = globals()[classifier_name]()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "    confusion_matrices[classifier_name] = conf_matrix\n",
        "\n",
        "for classifier_name in confusion_matrices.keys():\n",
        "    conf_matrix = confusion_matrices[classifier_name]\n",
        "    cm_plot = ConfusionMatrixDisplay(conf_matrix, display_labels=df['Satisfaction'].unique())\n",
        "    cm_plot.plot()"
      ],
      "metadata": {
        "id": "W8InjlvosIHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx0nCt98ds8F"
      },
      "source": [
        "### 6.4 KNeighborsClassifier\n",
        "Nous allons utiliser ici le KNeighborsClassifier associé à sa grille de paramètres spécfiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huT2so4WduBN"
      },
      "outputs": [],
      "source": [
        "classifier = KNeighborsClassifier()\n",
        "parameters = {\n",
        "    'model__n_neighbors' : range(1, 10, 2)\n",
        "}\n",
        "\n",
        "res_KNN = getClassifResults(classifier, parameters, data=df)\n",
        "print(res_KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.5 Random Forest Classifier\n"
      ],
      "metadata": {
        "id": "Jp7-AdAOZxry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier()\n",
        "parameters = {\n",
        "    'model__n_estimators' : range(50, 500, 50),\n",
        "    'model__criterion' : ('gini', 'entropy')\n",
        "}\n",
        "\n",
        "res_RF = getClassifResults(classifier, parameters, data=df)\n",
        "print(res_RF)"
      ],
      "metadata": {
        "id": "d_K_ODP4ZzwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZhkbYW1lsb3"
      },
      "source": [
        "### 6.6 HistGradient Boosting Classifier\n",
        "Nous allons utiliser ici le Gradient Boosting Classifier associé à sa grille de paramètres spécfiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8SN3fwtluPF"
      },
      "outputs": [],
      "source": [
        "classifier = HistGradientBoostingClassifier()\n",
        "parameters = {\n",
        "    'model__learning_rate' : np.arange (start=0.1, stop=0.9, step=0.1),\n",
        "    'model__loss' : ('auto', 'binary_crossentropy')\n",
        "    }\n",
        "\n",
        "res_HGB = getClassifResults(classifier, parameters, data=df)\n",
        "print(res_HGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BvkQBmVcULX"
      },
      "source": [
        "### 6.7 Synthèse\n",
        "Nous allons conserver et afficher tous les résulats dans une dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaXwXDTjcWF9"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(res_KNN,\n",
        "                          index=['Testing time (sec)', 'Training score (F1-score)', 'Training score (accuracy stratKfold)', 'Evaluation score (F1-score)', 'Evaluation score (accuracy stratKfold)', 'Best parameters'],\n",
        "                          columns=['KNeighborsClassifier'])\n",
        "results_df['HistGradient Boosting Classif'] = res_HGB\n",
        "results_df['Random Forest Classif'] = res_RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tkheMLQkJft"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPssekF+SkrP0f73lArqwK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}